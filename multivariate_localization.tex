\documentclass[12pt]{scrartcl}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{graphicx}
\usepackage{float}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{bm}
\usepackage{verbatim}
\usepackage[english]{babel}
\usepackage{color}
\usepackage{url}
\usepackage{fancybox}
\usepackage[stable]{footmisc}
\usepackage[format=plain,labelfont=bf]{caption}
\usepackage{fancyhdr}
\usepackage{natbib}
\usepackage{calc}
\usepackage{textcomp}
\usepackage[pdftex,pdfborder={0 0 0}]{hyperref}
\usepackage{pdfpages}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathmorphing}
\usepackage{amsmath}
\usepackage{easybmat}
\usepackage{multirow,bigdelim}

\renewcommand*{\familydefault}{\sfdefault}
\newcommand*\hexbrace[2]{%
  \underset{#2}{\underbrace{\rule{#1}{0pt}}}}
  
% Margins
\addtolength{\textheight}{1.0cm}
\addtolength{\oddsidemargin}{-0.5cm}
\addtolength{\evensidemargin}{-0.5cm}
\addtolength{\textwidth}{1.0cm}
\parindent=0em

% New math commands
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Diag}{Diag}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Cor}{Cor}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\setbox0\hbox{$#1#2$}%
\copy0\kern-\wd0\mkern4mu\box0}} 

% Appropriate font for \mathcal{}
\DeclareSymbolFont{cmmathcal}{OMS}{cmsy}{m}{n}
\DeclareSymbolFontAlphabet{\mathcal}{cmmathcal}

% Set subscript and superscripts positions
\everymath{
\fontdimen13\textfont2=5pt
\fontdimen14\textfont2=5pt
\fontdimen15\textfont2=5pt
\fontdimen16\textfont2=5pt
\fontdimen17\textfont2=5pt
}

% Bibliography style
\setlength{\bibsep}{1pt}

% Part
\renewcommand\partheadstartvskip{\clearpage\null\vfil}
\renewcommand\partheadmidvskip{\par\nobreak\vskip 20pt\thispagestyle{empty}}
\renewcommand\partheadendvskip{\vfil\clearpage}
\renewcommand\raggedpart{\centering}

\begin{document}
\title{Multivariate localization}
\author{Benjamin Ménétrier}
\date{Last update: \today}

\thispagestyle{empty}

\maketitle
\begin{center}
Documentation for the code "BUMP", distributed under the CeCILL-C license.\\
Copyright \copyright 2015-... UCAR, CERFACS, METEO-FRANCE and IRIT
\end{center}

\tableofcontents

\clearpage


\section{Framework}

\subsection{State vector definition}
The state vector $\mathbf{x} \in \mathbb{R}^n$ is split into $Q$ concatenated sub-vectors $\mathbf{x}_q$ (called ``groups''), each one gathering $P_q$ sub-vectors $\mathbf{x}_{p,q}$ of size $n_q$ (called ``variables''). Each sub-vector $\mathbf{x}_{p,q}$ corresponds to the data for a given physical variable (e.g. zonal wind, temperature, humidity, etc.). In a given group, all variables have the same size ($n_q$). Thus:
\begin{align}
\mathbf{x} = \left( \begin{array}{c}
\mathbf{x}_1 \\[1ex]
\hline
\vdots \\
\hline
\mathbf{x}_Q
\end{array} \right) \quad \text{and} \quad \mathbf{x}_q = \left( \begin{array}{c}
\mathbf{x}_{1,q} \\[1ex]
\hline
\vdots \\
\hline
\mathbf{x}_{P_q,q}
\end{array} \right) 
\end{align}
As a consequence:
\begin{itemize}
\item The total number of variables is $\displaystyle P = \sum_{q=1}^Q P_q$.
\item Each group $\mathbf{x}_q$ has a size $P_q n_q$, so the full state vector size is $n = \displaystyle \sum_{q=1}^Q P_q n_q$.
\end{itemize}
The main idea behind this distribution of variables into groups is to apply the same localization to all variables within a given group.\\

\subsection{Illustration setup}
A simple example will be used as an illustration throughout this note. We define a vector $\mathbf{x}$ with $Q = 3$ groups, where $P_1 = 3$, $P_2 = 1$ and $P_3 = 2$:
\begin{align}
\begin{array}{c@{}c}
\mathbf{x} = \left( \begin{array}{c}
\mathbf{x}_{1,1} \\
\mathbf{x}_{2,1} \\
\mathbf{x}_{3,1} \\[1ex]
\hline
\mathbf{x}_{1,2} \\[1ex]
\hline
\mathbf{x}_{1,3} \\
\mathbf{x}_{2,3}
\end{array} \right)
& 
\begin{array}{l}
\\[-8.5mm] \rdelim\}{3}{6mm}[$\mathbf{x}_1$ (1$^\text{st}$ group of variables)] \\[11.5mm] \rdelim\}{1}{6mm}[$\mathbf{x}_2$ (2$^\text{nd}$ group of variables)] \\[3.5mm] \rdelim\}{2}{6mm}[$\mathbf{x}_3$ (3$^\text{rd}$ group of variables)]
\end{array} \\[-1ex]
\end{array}
\end{align}

\subsection{Localization square-root}
The localization matrix $\mathbf{L} \in \mathbb{R}^{n \times n}$ is applied to $\mathbf{x}$. The main issue is to design a positive semi-definite $\mathbf{L}$ matrix, and the simplest solution is to build it as:
\begin{align}
\mathbf{L} = \mathbf{UU}^\textrm{T}
\end{align}
where $\mathbf{U} \in \mathbb{R}^{n \times m}$ is called a ``square-root'' of the localization matrix $\mathbf{L}$. The control vector $\mathbf{v} \in \mathbb{R}^m$ is such that:
\begin{align}
\mathbf{x} = \mathbf{U} \mathbf{v}
\end{align}
We can define a square-root component $\mathbf{U}_q \in \mathbb{R}^{n_q \times m_q}$ for each group.

\section{Possible implementations}

\subsection{Univariate localization}
For the case where there is no cross-localization between variables, the square-root $\mathbf{U}$ can be defined as:
\begin{align}
\mathbf{U} = \left( \begin{array}{ccc|c|cc}
\mathbf{U}_1 & 0 & 0 & 0 & 0 & 0 \\
0 & \mathbf{U}_1 & 0 & 0 & 0 & 0 \\
0 & 0 & \mathbf{U}_1 & 0 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & \mathbf{U}_2 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & \mathbf{U}_3 & 0 \\
0 & 0 & 0 & 0 & 0 & \mathbf{U}_3
\end{array} \right)
\end{align}
Thus:
\begin{align}
\mathbf{L} = \left( \begin{array}{ccc|c|cc}
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 & 0 & 0 \\
0 & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 & 0 \\
0 & 0 & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & \mathbf{U}_2 \mathbf{U}_2^\mathrm{T} & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & 0 \\
0 & 0 & 0 & 0 & 0 & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T}
\end{array} \right)
\end{align}
In this case, the total control vector size is $\displaystyle m = \sum_{q=1}^Q P_q m_q$

\subsection{Duplicated localization}
It is possible to define the cross-localization between the variables of a same group as duplicates of the diagonal localization, by defining $\mathbf{U}$ as: 
\begin{align}
\mathbf{U} & = \left( \begin{array}{c|c|c}
\mathbf{U}_1 & 0 & 0 \\
\mathbf{U}_1 & 0 & 0 \\
\mathbf{U}_1 & 0 & 0 \\[0.3ex]
\hline
0 & \mathbf{U}_2 & 0 \\[0.3ex]
\hline
0 & 0 & \mathbf{U}_3 \\
0 & 0 & \mathbf{U}_3
\end{array} \right) \nonumber \\
& = \left( \begin{array}{c|c|c}
\mathbf{I}_1 & 0 & 0 \\
\mathbf{I}_1 & 0 & 0 \\
\mathbf{I}_1 & 0 & 0 \\[0.3ex]
\hline
0 & \mathbf{I}_2 & 0 \\[0.3ex]
\hline
0 & 0 & \mathbf{I}_3 \\
0 & 0 & \mathbf{I}_3
\end{array} \right)
\left( \begin{array}{c|c|c}
\mathbf{U}_1 & 0 & 0 \\[0.3ex]
\hline
0 & \mathbf{U}_2 & 0 \\[0.3ex]
\hline
0 & 0 & \mathbf{U}_3
\end{array} \right)
\end{align}
where $\mathbf{I}_q \in \mathbf{R}^{n_q,n_q}$ is the identity matrix of size $n_q$. Thus:
\begin{align}
\mathbf{L} = \left( \begin{array}{ccc|c|cc}
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & \mathbf{U}_2 \mathbf{U}_2^\mathrm{T} & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} \\
0 & 0 & 0 & 0 & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T}
\end{array} \right)
\end{align}
In this case, the total control vector size is $\displaystyle m = \sum_{q=1}^Q m_q$

\subsection{Duplicated and weighted localization}
A variant of the previous case uses group-specific lower triangular matrices $\mathbf{S}^q \in \mathbb{R}^{P_q \times P_q}$ to define $\mathbf{U}$ as: 
\begin{align}
\mathbf{U} & = \left( \begin{array}{ccc|c|ccc}
S^1_{1,1} \mathbf{U}_1 & 0 & 0 & 0 & 0 & 0 \\
S^1_{2,1} \mathbf{U}_1 & S^1_{2,2} \mathbf{U}_1 & 0 & 0 & 0 & 0 \\
S^1_{3,1} \mathbf{U}_1 & S^1_{3,2} \mathbf{U}_1 & S^1_{3,3} \mathbf{U}_1 & 0 & 0 & 0 \\
\hline
0 & 0 & 0 & S^2_{1,1} \mathbf{U}_2 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & S^3_{1,1} \mathbf{U}_3 & 0 \\
0 & 0 & 0 & 0 & S^3_{2,1} \mathbf{U}_3 & S^3_{2,2} \mathbf{U}_3
\end{array} \right) \nonumber \\
& = \left( \begin{array}{ccc|c|ccc}
S^1_{1,1} \mathbf{I}_1 & 0 & 0 & 0 & 0 & 0 \\
S^1_{2,1} \mathbf{I}_1 & S^1_{2,2} \mathbf{I}_1 & 0 & 0 & 0 & 0 \\
S^1_{3,1} \mathbf{I}_1 & S^1_{3,2} \mathbf{I}_1 & S^1_{3,3} \mathbf{I}_1 & 0 & 0 & 0 \\
\hline
0 & 0 & 0 & S^2_{1,1} \mathbf{I}_2 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & S^3_{1,1} \mathbf{I}_3 & 0 \\
0 & 0 & 0 & 0 & S^3_{2,1} \mathbf{I}_3 & S^3_{2,1} \mathbf{I}_3
\end{array} \right) \left( \begin{array}{ccc|c|cc}
\mathbf{U}_1 & 0 & 0 & 0 & 0 & 0 \\
0 & \mathbf{U}_1 & 0 & 0 & 0 & 0 \\
0 & 0 & \mathbf{U}_1 & 0 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & \mathbf{U}_2 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & \mathbf{U}_3 & 0 \\
0 & 0 & 0 & 0 & 0 & \mathbf{U}_3
\end{array} \right)
\end{align}
Thus:
\begin{align}
\mathbf{L} = \left( \begin{array}{ccc|c|cc}
W^1_{1,1} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{1,2} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{1,3} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\
W^1_{2,1} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{2,2} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{2,3} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\
W^1_{3,1} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{3,2} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & W^1_{3,3} \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & 0 & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & W^2_{1,1} \mathbf{U}_2 \mathbf{U}_2^\mathrm{T} & 0 & 0 \\[0.3ex]
\hline
0 & 0 & 0 & 0 & W^3_{1,1} \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & W^3_{1,2} \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} \\
0 & 0 & 0 & 0 & W^3_{2,1} \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & W^3_{2,2} \mathbf{U}_3 \mathbf{U}_3^\mathrm{T}
\end{array} \right)
\end{align}
where $\mathbf{W}^q = \mathbf{S}^q \mathbf{S}^{q\mathrm{T}}$ provides the weights applied to each covariance between variables within the group $q$. In practice, it is easier to set $\mathbf{W}^q$ and to compute $\mathbf{S}^q$ using a Cholesky decomposition. It also seems reasonable to set the diagonal elements of $\mathbf{W}^q$ to one, even if it is not mandatory.\\
$  $\\
In this case, the total control vector size is $\displaystyle m = \sum_{q=1}^Q P_q m_q$

\subsection{Multivariate localization}
For the case where the cross-localization between variables is implicitly given as the product of square-roots, $\mathbf{U}$ can be reduced to a column:
\begin{align}
\mathbf{U} & = \left( \begin{array}{c}
\mathbf{U}_1 \\
\mathbf{U}_1 \\
\mathbf{U}_1 \\[0.3ex]
\hline
\mathbf{U}_2 \\[0.3ex]
\hline
\mathbf{U}_3 \\
\mathbf{U}_3
\end{array} \right) \nonumber \\
& = \left( \begin{array}{c|c|c}
\mathbf{I}_1 & 0 & 0 \\
\mathbf{I}_1 & 0 & 0 \\
\mathbf{I}_1 & 0 & 0 \\[0.3ex]
\hline
0 & \mathbf{I}_2 & 0 \\[0.3ex]
\hline
0 & 0 & \mathbf{I}_3 \\
0 & 0 & \mathbf{I}_3
\end{array} \right)
\left( \begin{array}{c}
\mathbf{U}_1 \\[0.3ex]
\hline
\mathbf{U}_2 \\[0.3ex]
\hline
\mathbf{U}_3
\end{array} \right)
\end{align}
An additional assumption is required here: the size of the group sub-vectors must be the same for all groups, i.e. $m_1 = ... = m_Q = \overbar{m}$. Thus:
\begin{align}
\mathbf{L} = \left( \begin{array}{ccc|c|cc}
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} \\
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} \\
\mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_1 \mathbf{U}_3^\mathrm{T} \\[0.3ex]
\hline
\mathbf{U}_2 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_2 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_2 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_2 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_2 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_2 \mathbf{U}_3^\mathrm{T} \\[0.3ex]
\hline
\mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} \\
\mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_1^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_2^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T} & \mathbf{U}_3 \mathbf{U}_3^\mathrm{T}
\end{array} \right)
\end{align}
In this case, the total control vector size is $\displaystyle m = \overbar{m}$.\\
$  $\\
The amplitude of cross-localization is not one in this case. For $1 \le q,q' \le Q$, we denote $\mathbf{u}$ the k$^\textrm{th}$ column of $\mathbf{U}_q$ and $\mathbf{u}'$ the k$^\textrm{th}$ column of $\mathbf{U}_{q'}$. The k$^\textrm{th}$ diagonal coefficient of $\mathbf{U}_q \mathbf{U}_{q'}^\mathrm{T}$ is given by $\langle \mathbf{u},\mathbf{u}' \rangle$, where $\langle \cdot, \cdot \rangle$ denotes the canonical inner product. The Cauchy-Schwartz inequality requires that:
\begin{align}
\vert \langle \mathbf{u},\mathbf{u}' \rangle \vert & \le \sqrt{\langle \mathbf{u},\mathbf{u} \rangle \langle \mathbf{u}',\mathbf{u}' \rangle}
\end{align}
Thus, the cross-localization amplitude between groups $q$ and $q'$ is necessarily smaller than the geometric mean of the auto-localization amplitudes for groups $q$ and $q'$. Besides, the more the vectors $\mathbf{u}$ and $\mathbf{u}'$ have different shapes, the smaller their inner product and the smaller the cross-localization amplitude.
\begin{center}
\includegraphics[width=\linewidth]{convolution_exp.pdf}
\captionof{figure}{1D illustration of the product of two localization square-root, with Gaussian localization functions. The dashed black line shows the function amplitude, while the solid red line shows the function length-scale.}
\end{center}

\bibliographystyle{mybib-en}
\bibliography{multivariate_localization}
\end{document}
